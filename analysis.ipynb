{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d35873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# --- 1. Interpretation of K-Means Clusters ---\n",
    "def analyze_clusters(kmeans_model, vectorizer, final_df, K=5):\n",
    "    \"\"\"Interprets K-Means clusters by finding the top words in each cluster center.\"\"\"\n",
    "    \n",
    "    print(\"\\n--- Cluster Analysis: Customer Segments ---\")\n",
    "    print(\"Cluster Distribution:\")\n",
    "    print(final_df['cluster'].value_counts())\n",
    "    \n",
    "    vectorizer_names = vectorizer.get_feature_names_out()\n",
    "    cluster_centers = kmeans_model.cluster_centers_\n",
    "\n",
    "    print(\"\\nTop words (features) for each cluster:\")\n",
    "    for i in range(K):\n",
    "        # Get indices of the top 10 highest TF-IDF scores for this cluster center\n",
    "        top_indices = cluster_centers[i].argsort()[-10:][::-1]\n",
    "        top_features = [vectorizer_names[j] for j in top_indices]\n",
    "        print(f\"Cluster {i}: {', '.join(top_features)}\")\n",
    "    \n",
    "\n",
    "# --- 2. Interpretation of Logistic Regression Coefficients ---\n",
    "def analyze_feature_importance(lr_model, X_train, y_train, vectorizer):\n",
    "    \"\"\"Extracts and prints the top positive and negative feature drivers.\"\"\"\n",
    "    \n",
    "    # Re-train the model if the provided one doesn't have coefficients attached\n",
    "    if not hasattr(lr_model, 'coef_'):\n",
    "        print(\"Model coefficients not found. Retraining Logistic Regression...\")\n",
    "        lr_model.fit(X_train, y_train)\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    classes = lr_model.classes_\n",
    "    coef = lr_model.coef_\n",
    "\n",
    "    print(\"\\n--- Sentiment Feature Importance Analysis (Logistic Regression) ---\")\n",
    "\n",
    "    # Positive Features\n",
    "    positive_class_index = list(classes).index('Positive')\n",
    "    top_positive_indices = coef[positive_class_index].argsort()[-10:][::-1]\n",
    "    top_positive_words = [feature_names[i] for i in top_positive_indices]\n",
    "    print(f\"Top 10 Words Driving POSITIVE Sentiment: \\n{', '.join(top_positive_words)}\")\n",
    "    \n",
    "\n",
    "[Image of a feature importance plot showing positive vs negative coefficients in a linear model]\n",
    "\n",
    "\n",
    "    # Negative Features\n",
    "    negative_class_index = list(classes).index('Negative')\n",
    "    top_negative_indices = coef[negative_class_index].argsort()[-10:][::-1]\n",
    "    top_negative_words = [feature_names[i] for i in top_negative_indices]\n",
    "    print(f\"\\nTop 10 Words Driving NEGATIVE Sentiment: \\n{', '.join(top_negative_words)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
